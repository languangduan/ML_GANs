nohup: ignoring input
2024-10-29 18:26:10,956 - INFO - Hyperparameters:
2024-10-29 18:26:10,956 - INFO - data_dir: datasets
2024-10-29 18:26:10,956 - INFO - epochs: 45
2024-10-29 18:26:10,956 - INFO - batch_size: 4
2024-10-29 18:26:10,956 - INFO - lr: 0.0002
2024-10-29 18:26:10,956 - INFO - beta1: 0.5
2024-10-29 18:26:10,956 - INFO - beta2: 0.999
2024-10-29 18:26:10,956 - INFO - model_save_dir: ./checkpoints
2024-10-29 18:26:10,956 - INFO - img_save_dir: generated_imgs
2024-10-29 18:26:10,956 - INFO - log_save_dir: logs
2024-10-29 18:26:10,956 - INFO - device: cuda:0
2024-10-29 18:26:10,956 - INFO - lambda_cycle: 10.0
2024-10-29 18:26:10,956 - INFO - seed: 42
2024-10-29 18:26:11,834 - INFO - Loading pretrained weights from url (https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth)
2024-10-29 18:26:13,084 - INFO - Loading pretrained weights from url (https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth)
/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-10-29 18:26:13,840 - INFO - Generated dataloaders from datasets
Using device: cuda:0
Epoch 1/45
Traceback (most recent call last):
  File "/scratch/yiyang/ML_GANs/main.py", line 127, in <module>
    main()
  File "/scratch/yiyang/ML_GANs/main.py", line 122, in main
    train_cyclegan(cyclegan, train_loader, val_loader, args.epochs, device, args.model_save_dir,
  File "/scratch/yiyang/ML_GANs/main.py", line 28, in train_cyclegan
    losses = cyclegan.train_step(real_monet, real_photo)
  File "/scratch/yiyang/ML_GANs/models/CycleGan.py", line 40, in train_step
    same_monet = self.m_gen(real_monet)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/backbones_unet/model/unet.py", line 140, in forward
    x = self.encoder(x)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/timm/models/features.py", line 232, in forward
    return list(self._collect(x).values())
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/timm/models/features.py", line 203, in _collect
    x = module(x)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/timm/models/convnext.py", line 250, in forward
    x = self.blocks(x)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/timm/models/convnext.py", line 184, in forward
    x = self.mlp(x)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/timm/models/layers/mlp.py", line 30, in forward
    x = self.fc2(x)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/yiyang/anaconda3/envs/dyy/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.46 GiB of which 13.38 MiB is free. Process 1225752 has 15.03 GiB memory in use. Process 1248898 has 1.81 GiB memory in use. Including non-PyTorch memory, this process has 6.59 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 34.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
